{"assessment_methods": {"practical_performance": {"name": "Practical Performance (PP)", "description": "A practical Performance (PP) assessment will provide direct evidence of whether candidates have acquired the competency for the ability statements by solving a scenario-based problem.", "focus": "The Practical Performance (PP) assessment focuses on providing authentic 'Show Me Application' evidence of candidates' ability to develop and fine-tune generative AI models using deep learning frameworks.", "tasks": ["Candidates will complete a comprehensive project implementing, training, and fine-tuning generative AI models on benchmark datasets using appropriate machine learning libraries."], "evidence": {"LO1": "Candidates will implement generative models using deep learning algorithms and analyze their suitability for different problem requirements.", "LO2": "Candidates will preprocess datasets using embeddings and tokenization techniques for model readiness.", "LO3": "Candidates will train generative AI models with neural optimization techniques using benchmark datasets.", "LO4": "Candidates will identify model weaknesses and propose targeted fine-tuning strategies for improvement."}, "submission": ["Candidates will submit their complete code implementation, trained model files, and evaluation reports demonstrating the entire development pipeline.", "This includes preprocessing scripts, training logs, performance metrics, and fine-tuning documentation."], "marking_process": ["Model Implementation Quality", "Data Preprocessing Accuracy", "Training and Fine-tuning Effectiveness"], "retention_period": "All submitted evidence, including code files, model outputs, and assessment records, will be retained for 3 years to ensure compliance with institutional policies and for auditing purposes."}}}